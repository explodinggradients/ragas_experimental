# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/metric/llm.ipynb.

# %% auto 0
__all__ = ['T', 'RagasLLM', 'ragas_llm']

# %% ../../nbs/metric/llm.ipynb 2
import typing as t
import asyncio
import inspect
from pydantic import BaseModel
import instructor

T = t.TypeVar('T', bound=BaseModel)

class RagasLLM:
    def __init__(self, provider: str, client: t.Any, model: t.Optional[str] = None):
        self.provider = provider.lower()
        self.model = model
        self.client = self._initialize_client(provider, client)
        # Check if client is async-capable at initialization
        self.is_async = self._check_client_async()
    
    def _check_client_async(self) -> bool:
        """Determine if the client is async-capable."""
        try:
            # Check if this is an async client by checking for a coroutine method
            if hasattr(self.client.chat.completions, 'create'):
                return inspect.iscoroutinefunction(self.client.chat.completions.create)
            return False
        except (AttributeError, TypeError):
            return False
    
    def _initialize_client(self, provider: str, client: t.Any) -> t.Any:
        provider = provider.lower()
        
        if provider == "openai":
            return instructor.from_openai(client)
        elif provider == "anthropic":
            return instructor.from_anthropic(client)
        elif provider == "cohere":
            return instructor.from_cohere(client)
        elif provider == "gemini":
            return instructor.from_gemini(client)
        elif provider == "litellm":
            return instructor.from_litellm(client)
        else:
            raise ValueError(f"Unsupported provider: {provider}")
    
    def _run_async_in_current_loop(self, coro):
        """Run an async coroutine in the current event loop if possible.
        
        This handles Jupyter environments correctly by using the existing loop.
        """
        try:
            # Check if we're in an environment with an existing event loop (like Jupyter)
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # We're likely in a Jupyter environment
                import nest_asyncio
                nest_asyncio.apply()
            return loop.run_until_complete(coro)
        except RuntimeError:
            # If we get a runtime error about no event loop, create a new one
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(coro)
            finally:
                loop.close()
                asyncio.set_event_loop(None)
    
    def generate(self, prompt: str, response_model: t.Type[T], **kwargs) -> T:
        """Generate a response using the configured LLM.
        
        For async clients, this will run the async method in the appropriate event loop.
        """
        messages = [{"role": "user", "content": prompt}]
        if "model" not in kwargs and self.model:
            kwargs["model"] = self.model
        
        # If client is async, use the appropriate method to run it
        if self.is_async:
            return self._run_async_in_current_loop(
                self.agenerate(prompt, response_model, **kwargs)
            )
        else:
            # Regular sync client, just call the method directly
            return self.client.chat.completions.create(
                messages=messages,
                response_model=response_model,
                **kwargs
            )
    
    async def agenerate(self, prompt: str, response_model: t.Type[T], **kwargs) -> T:
        """Asynchronously generate a response using the configured LLM."""
        messages = [{"role": "user", "content": prompt}]
        if "model" not in kwargs and self.model:
            kwargs["model"] = self.model
        
        # If client is not async, raise a helpful error
        if not self.is_async:
            raise TypeError(
                "Cannot use agenerate() with a synchronous client. Use generate() instead."
            )
        
        # Regular async client, call the method directly
        return await self.client.chat.completions.create(
            messages=messages,
            response_model=response_model,
            **kwargs
        )

def ragas_llm(provider: str, client: t.Any, model: t.Optional[str] = None) -> RagasLLM:
    return RagasLLM(provider=provider, client=client, model=model)
