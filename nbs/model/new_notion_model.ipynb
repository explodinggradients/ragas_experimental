{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Ragas Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ConfigDict, PrivateAttr, create_model, ValidationError\n",
    "import typing as t\n",
    "from datetime import datetime\n",
    "import inspect\n",
    "\n",
    "# Type variable for generic models\n",
    "T = t.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "# Base metadata class for Notion field types\n",
    "class NotionFieldMeta:\n",
    "    \"\"\"Base metadata class for Notion field types.\"\"\"\n",
    "\n",
    "    NOTION_FIELD_TYPE: t.ClassVar[str] = \"\"\n",
    "    required: bool = True\n",
    "    name: str = \"\"\n",
    "    _instance_cache = {}  # Global instance cache\n",
    "\n",
    "    def __class_getitem__(cls, params):\n",
    "        \"\"\"Support for Class[field_type] syntax\"\"\"\n",
    "        return cls\n",
    "\n",
    "    def __new__(cls, required=True):\n",
    "        \"\"\"Create a new instance or return a cached one\"\"\"\n",
    "        if cls not in NotionFieldMeta._instance_cache:\n",
    "            NotionFieldMeta._instance_cache[cls] = {}\n",
    "\n",
    "        key = (cls, required)\n",
    "        if key not in NotionFieldMeta._instance_cache[cls]:\n",
    "            instance = super().__new__(cls)\n",
    "            instance.required = required\n",
    "            NotionFieldMeta._instance_cache[cls][key] = instance\n",
    "\n",
    "        return NotionFieldMeta._instance_cache[cls][key]\n",
    "\n",
    "    def __call__(self, required=True):\n",
    "        \"\"\"Support both Class and Class() syntax\"\"\"\n",
    "        return self.__class__(required=required)\n",
    "\n",
    "    def validate(self, value: t.Any) -> t.Any:\n",
    "        \"\"\"Validate field value.\"\"\"\n",
    "        if value is None and self.required:\n",
    "            raise ValueError(f\"Field {self.name} is required\")\n",
    "        return value\n",
    "\n",
    "    def to_notion(self, value: t.Any) -> dict:\n",
    "        \"\"\"Convert Python value to Notion format.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def from_notion(self, data: dict) -> t.Any:\n",
    "        \"\"\"Convert Notion format to Python value.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_notion_property(self) -> dict:\n",
    "        \"\"\"Define Notion property schema for database creation.\"\"\"\n",
    "        return {self.name: {\"type\": self.NOTION_FIELD_TYPE, self.NOTION_FIELD_TYPE: {}}}\n",
    "\n",
    "\n",
    "# Implementation of field types\n",
    "class ID(NotionFieldMeta):\n",
    "    \"\"\"Notion ID field type.\"\"\"\n",
    "\n",
    "    NOTION_FIELD_TYPE = \"unique_id\"\n",
    "\n",
    "    def validate(self, value: t.Any) -> t.Optional[int]:\n",
    "        value = super().validate(value)\n",
    "        if value is not None and not isinstance(value, int):\n",
    "            raise ValueError(f\"ID must be an integer, got {type(value)}\")\n",
    "        return value\n",
    "\n",
    "    def to_notion(self, value: int) -> dict:\n",
    "        return {self.name: {\"type\": \"unique_id\", \"unique_id\": value}}\n",
    "\n",
    "    def from_notion(self, data: dict) -> t.Optional[int]:\n",
    "        if \"properties\" in data and self.name in data[\"poperties\"]:\n",
    "            unique_id = data[\"properties\"][self.name][\"unique_id\"]\n",
    "            # Handle both integer values and structured API responses\n",
    "            if isinstance(unique_id, int):\n",
    "                return unique_id\n",
    "            elif isinstance(unique_id, dict) and \"number\" in unique_id:\n",
    "                return unique_id[\"number\"]\n",
    "        elif self.name in data:\n",
    "            unique_id = data[self.name][\"unique_id\"]\n",
    "            # Handle both integer values and structured API responses\n",
    "            if isinstance(unique_id, int):\n",
    "                return unique_id\n",
    "            elif isinstance(unique_id, dict) and \"number\" in unique_id:\n",
    "                return unique_id[\"number\"]\n",
    "            return None\n",
    "\n",
    "    def to_notion_property(self) -> dict:\n",
    "        return {self.name: {\"type\": \"unique_id\", \"unique_id\": {\"prefix\": None}}}\n",
    "\n",
    "\n",
    "class Text(NotionFieldMeta):\n",
    "    \"\"\"Notion rich text field type.\"\"\"\n",
    "\n",
    "    NOTION_FIELD_TYPE = \"rich_text\"\n",
    "    CHUNK_SIZE = 2000  # Notion's character limit per rich text block\n",
    "\n",
    "    def validate(self, value: t.Any) -> t.Optional[str]:\n",
    "        value = super().validate(value)\n",
    "        if value is not None and not isinstance(value, str):\n",
    "            raise ValueError(f\"Text must be a string, got {type(value)}\")\n",
    "        return value\n",
    "\n",
    "    def to_notion(self, value: str) -> dict:\n",
    "        if not value:\n",
    "            return {self.name: {self.NOTION_FIELD_TYPE: []}}\n",
    "\n",
    "        chunks = [\n",
    "            value[i : i + self.CHUNK_SIZE]\n",
    "            for i in range(0, len(value), self.CHUNK_SIZE)\n",
    "        ]\n",
    "        rich_text_array = [{\"text\": {\"content\": chunk}} for chunk in chunks]\n",
    "\n",
    "        return {self.name: {self.NOTION_FIELD_TYPE: rich_text_array}}\n",
    "\n",
    "    def from_notion(self, data: dict) -> t.Optional[str]:\n",
    "        if \"properties\" in data and self.name in data[\"properties\"]:\n",
    "            rich_text = data[\"properties\"][self.name][self.NOTION_FIELD_TYPE]\n",
    "        elif self.name in data:\n",
    "            rich_text = data[self.name][self.NOTION_FIELD_TYPE]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if not rich_text:\n",
    "            return None\n",
    "\n",
    "        return \"\".join(item[\"text\"][\"content\"] for item in rich_text if \"text\" in item)\n",
    "\n",
    "\n",
    "class Select(NotionFieldMeta):\n",
    "    \"\"\"Notion select field type.\"\"\"\n",
    "\n",
    "    NOTION_FIELD_TYPE = \"select\"\n",
    "    options: list = []\n",
    "\n",
    "    def __new__(cls, options=None, required=True):\n",
    "        \"\"\"Create a new instance or return a cached one\"\"\"\n",
    "        if cls not in NotionFieldMeta._instance_cache:\n",
    "            NotionFieldMeta._instance_cache[cls] = {}\n",
    "\n",
    "        key = (cls, tuple(options) if options else None, required)\n",
    "        if key not in NotionFieldMeta._instance_cache[cls]:\n",
    "            instance = super(NotionFieldMeta, cls).__new__(cls)\n",
    "            instance.required = required\n",
    "            instance.options = options\n",
    "            NotionFieldMeta._instance_cache[cls][key] = instance\n",
    "\n",
    "        return NotionFieldMeta._instance_cache[cls][key]\n",
    "\n",
    "    def __init__(self, options=None, required=True):\n",
    "        self.required = required\n",
    "        self.options = options\n",
    "\n",
    "    def validate(self, value: t.Any) -> t.Optional[str]:\n",
    "        value = super().validate(value)\n",
    "        if value is not None:\n",
    "            if not isinstance(value, str):\n",
    "                raise ValueError(f\"Select value must be a string, got {type(value)}\")\n",
    "\n",
    "            # Check options or extract from Literal type\n",
    "            options = self.options\n",
    "            if not options:\n",
    "                # We'll extract options later when we have field info\n",
    "                pass\n",
    "            elif options and value not in options:\n",
    "                raise ValueError(\n",
    "                    f\"Value '{value}' is not in allowed options: {options}\"\n",
    "                )\n",
    "        return value\n",
    "\n",
    "    def to_notion(self, value: str) -> dict:\n",
    "        if not value:\n",
    "            return {self.name: {self.NOTION_FIELD_TYPE: None}}\n",
    "        return {self.name: {self.NOTION_FIELD_TYPE: {\"name\": value}}}\n",
    "\n",
    "    def from_notion(self, data: dict) -> t.Optional[str]:\n",
    "        if \"properties\" in data and self.name in data[\"properties\"]:\n",
    "            select_data = data[\"properties\"][self.name][self.NOTION_FIELD_TYPE]\n",
    "        elif self.name in data:\n",
    "            select_data = data[self.name][self.NOTION_FIELD_TYPE]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if not select_data:\n",
    "            return None\n",
    "\n",
    "        return select_data[\"name\"]\n",
    "\n",
    "    def to_notion_property(self) -> dict:\n",
    "        options = [{\"name\": option} for option in (self.options or [])]\n",
    "        return {self.name: {\"type\": \"select\", \"select\": {\"options\": options}}}\n",
    "\n",
    "\n",
    "# Convenience alias\n",
    "Title = Text  # For clarity when using as a title\n",
    "\n",
    "\n",
    "# The main Notion model base class\n",
    "class NotionModel(BaseModel):\n",
    "    \"\"\"Base model for Notion integration with Pydantic.\"\"\"\n",
    "\n",
    "    model_config = ConfigDict(extra=\"forbid\", arbitrary_types_allowed=True)\n",
    "\n",
    "    # Notion metadata stored as private attributes\n",
    "    _page_id: t.Optional[str] = PrivateAttr(default=None)\n",
    "    _created_time: t.Optional[datetime] = PrivateAttr(default=None)\n",
    "    _last_edited_time: t.Optional[datetime] = PrivateAttr(default=None)\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        # Extract Notion metadata before validation\n",
    "        page_id = data.pop(\"page_id\", None)\n",
    "        created_time = data.pop(\"created_time\", None)\n",
    "        last_edited_time = data.pop(\"last_edited_time\", None)\n",
    "\n",
    "        # Process field metadata\n",
    "        self._process_field_metadata()\n",
    "\n",
    "        # Pre-validate field data against Notion field metadata\n",
    "        self._validate_notion_fields(data)\n",
    "\n",
    "        # Initialize using Pydantic\n",
    "        super().__init__(**data)\n",
    "\n",
    "        # Set private attributes after initialization\n",
    "        self._page_id = page_id\n",
    "        self._created_time = created_time\n",
    "        self._last_edited_time = last_edited_time\n",
    "\n",
    "    def _process_field_metadata(self):\n",
    "        \"\"\"Process field metadata to handle class references and Literal types.\"\"\"\n",
    "        for field_name, field_info in self.model_fields.items():\n",
    "            updated_metadata = list(field_info.metadata)\n",
    "            for i, meta in enumerate(updated_metadata):\n",
    "                # If the metadata is a NotionFieldMeta class (not instance), instantiate it\n",
    "                if inspect.isclass(meta) and issubclass(meta, NotionFieldMeta):\n",
    "                    updated_metadata[i] = meta()\n",
    "\n",
    "                # Set field name for the metadata\n",
    "                if isinstance(meta, NotionFieldMeta):\n",
    "                    meta.name = field_name\n",
    "\n",
    "                    # Handle Select fields with Literal type\n",
    "                    if isinstance(meta, Select) and not meta.options:\n",
    "                        origin = t.get_origin(field_info.annotation)\n",
    "                        if origin is t.Annotated:\n",
    "                            # Get the real type from Annotated\n",
    "                            real_type = t.get_args(field_info.annotation)[0]\n",
    "                            origin = t.get_origin(real_type)\n",
    "                            if origin is t.Literal:\n",
    "                                meta.options = list(t.get_args(real_type))\n",
    "\n",
    "            # Update the field metadata\n",
    "            field_info.metadata = tuple(updated_metadata)\n",
    "\n",
    "    def _validate_notion_fields(self, data: dict):\n",
    "        \"\"\"Pre-validate data against Notion field metadata.\"\"\"\n",
    "        errors = []\n",
    "\n",
    "        for field_name, field_info in self.model_fields.items():\n",
    "            if field_name in data:\n",
    "                value = data[field_name]\n",
    "\n",
    "                for meta in field_info.metadata:\n",
    "                    if isinstance(meta, NotionFieldMeta):\n",
    "                        try:\n",
    "                            meta.validate(value)\n",
    "                        except ValueError as e:\n",
    "                            errors.append(\n",
    "                                {\n",
    "                                    \"loc\": (field_name,),\n",
    "                                    \"msg\": str(e),\n",
    "                                    \"type\": \"value_error\",\n",
    "                                    \"input\": value,\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "        if errors:\n",
    "            raise ValidationError.from_exception_data(\n",
    "                title=f\"Validation error for {self.__class__.__name__}\",\n",
    "                line_errors=errors,\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def page_id(self) -> t.Optional[str]:\n",
    "        \"\"\"Get the Notion page ID.\"\"\"\n",
    "        return self._page_id\n",
    "\n",
    "    def to_notion(self) -> dict:\n",
    "        \"\"\"Convert model to Notion format.\"\"\"\n",
    "        result = {\"properties\": {}}\n",
    "\n",
    "        for field_name, field_info in self.model_fields.items():\n",
    "            for meta in field_info.metadata:\n",
    "                if isinstance(meta, NotionFieldMeta):\n",
    "                    value = getattr(self, field_name)\n",
    "                    if value is not None:  # Skip None values\n",
    "                        notion_data = meta.to_notion(value)\n",
    "                        result[\"properties\"].update(notion_data)\n",
    "\n",
    "        # Add page_id if it exists\n",
    "        if self._page_id:\n",
    "            result[\"id\"] = self._page_id\n",
    "\n",
    "        return result\n",
    "\n",
    "    @classmethod\n",
    "    def from_notion(cls, data: dict):\n",
    "        \"\"\"Create model instance from Notion data.\"\"\"\n",
    "        values = {}\n",
    "\n",
    "        # Process fields based on metadata\n",
    "        for field_name, field_info in cls.model_fields.items():\n",
    "            for meta in field_info.metadata:\n",
    "                if isinstance(meta, NotionFieldMeta):\n",
    "                    meta.name = field_name  # Ensure name is set\n",
    "                    value = meta.from_notion(data)\n",
    "                    if value is not None:\n",
    "                        values[field_name] = value\n",
    "\n",
    "        # Include Notion metadata\n",
    "        notion_metadata = {}\n",
    "        if \"id\" in data:\n",
    "            notion_metadata[\"page_id\"] = data[\"id\"]\n",
    "        if \"created_time\" in data:\n",
    "            notion_metadata[\"created_time\"] = data[\"created_time\"]\n",
    "        if \"last_edited_time\" in data:\n",
    "            notion_metadata[\"last_edited_time\"] = data[\"last_edited_time\"]\n",
    "\n",
    "        # Create instance\n",
    "        instance = cls(**values)\n",
    "\n",
    "        # Set private attributes\n",
    "        if \"page_id\" in notion_metadata:\n",
    "            instance._page_id = notion_metadata[\"page_id\"]\n",
    "        if \"created_time\" in notion_metadata:\n",
    "            instance._created_time = notion_metadata[\"created_time\"]\n",
    "        if \"last_edited_time\" in notion_metadata:\n",
    "            instance._last_edited_time = notion_metadata[\"last_edited_time\"]\n",
    "\n",
    "        return instance\n",
    "\n",
    "    def get_notion_properties(self) -> dict:\n",
    "        \"\"\"Get Notion property definitions for creating database.\"\"\"\n",
    "        properties = {}\n",
    "\n",
    "        for field_name, field_info in self.model_fields.items():\n",
    "            for meta in field_info.metadata:\n",
    "                if isinstance(meta, NotionFieldMeta):\n",
    "                    meta.name = field_name\n",
    "                    properties.update(meta.to_notion_property())\n",
    "\n",
    "        return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class SupermeDataset(NotionModel):\n",
    "    id: t.Annotated[int, ID]\n",
    "    query: t.Annotated[str, Title]\n",
    "    persona: t.Annotated[t.Literal[\"user\", \"agent\"], Select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid instance created: {\"id\":1,\"query\":\"test query\",\"persona\":\"user\"}\n",
      "Validation failed as expected: 1 validation error for SupermeDataset\n",
      "persona\n",
      "  Input should be 'user' or 'agent' [type=literal_error, input_value='invalid', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "Notion format: {'properties': {'id': {'type': 'unique_id', 'unique_id': 1}, 'query': {'rich_text': [{'text': {'content': 'test query'}}]}, 'persona': {'select': {'name': 'user'}}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'poperties'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create from Notion data\u001b[39;00m\n\u001b[32m     17\u001b[39m notion_response = {\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpage_123\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproperties\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlast_edited_time\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m2023-01-02T00:00:00Z\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m ds_from_notion = \u001b[43mSupermeDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_notion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotion_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFrom Notion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_from_notion.model_dump_json()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPage ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_from_notion.page_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 319\u001b[39m, in \u001b[36mNotionModel.from_notion\u001b[39m\u001b[34m(cls, data)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(meta, NotionFieldMeta):\n\u001b[32m    318\u001b[39m     meta.name = field_name  \u001b[38;5;66;03m# Ensure name is set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     value = \u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_notion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    321\u001b[39m         values[field_name] = value\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mID.from_notion\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_notion\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) -> t.Optional[\u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproperties\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpoperties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     76\u001b[39m         unique_id = data[\u001b[33m\"\u001b[39m\u001b[33mproperties\u001b[39m\u001b[33m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m.name][\u001b[33m\"\u001b[39m\u001b[33munique_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     77\u001b[39m         \u001b[38;5;66;03m# Handle both integer values and structured API responses\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'poperties'"
     ]
    }
   ],
   "source": [
    "# This should work\n",
    "ds1 = SupermeDataset(id=1, query=\"test query\", persona=\"user\")\n",
    "print(f\"Valid instance created: {ds1.model_dump_json()}\")\n",
    "\n",
    "# This should fail validation with an error\n",
    "try:\n",
    "    ds2 = SupermeDataset(id=1, query=\"test query\", persona=\"invalid\")\n",
    "    print(\"This should not print!\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation failed as expected: {e}\")\n",
    "\n",
    "# Convert to Notion format\n",
    "notion_data = ds1.to_notion()\n",
    "print(f\"Notion format: {notion_data}\")\n",
    "\n",
    "# Create from Notion data\n",
    "notion_response = {\n",
    "    \"id\": \"page_123\",\n",
    "    \"properties\": {\n",
    "        \"id\": {\"type\": \"unique_id\", \"unique_id\": 42},\n",
    "        \"query\": {\"rich_text\": [{\"text\": {\"content\": \"from notion\"}}]},\n",
    "        \"persona\": {\"select\": {\"name\": \"agent\"}},\n",
    "    },\n",
    "    \"created_time\": \"2023-01-01T00:00:00Z\",\n",
    "    \"last_edited_time\": \"2023-01-02T00:00:00Z\",\n",
    "}\n",
    "\n",
    "ds_from_notion = SupermeDataset.from_notion(notion_response)\n",
    "print(f\"From Notion: {ds_from_notion.model_dump_json()}\")\n",
    "print(f\"Page ID: {ds_from_notion.page_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the API Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGAS_APP_TOKEN = \"apt.47bd-c55e4a45b27c-02f8-8446-1441f09b-651a8\"\n",
    "RAGAS_API_ENDPOINT = \"http://localhost:8087\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import typing as t\n",
    "\n",
    "\n",
    "class RelayClient:\n",
    "    \"\"\"Async client for the Relay API.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str, app_token: t.Optional[str] = None):\n",
    "        if not app_token:\n",
    "            raise ValueError(\"app_token must be provided\")\n",
    "\n",
    "        self.base_url = f\"{base_url.rstrip('/')}/api/v1\"\n",
    "        self.app_token = app_token\n",
    "\n",
    "    async def _request(\n",
    "        self,\n",
    "        method: str,\n",
    "        endpoint: str,\n",
    "        params: t.Optional[t.Dict] = None,\n",
    "        json_data: t.Optional[t.Dict] = None,\n",
    "    ) -> t.Dict:\n",
    "        \"\"\n",
    "        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n",
    "        headers = {}\n",
    "        headers[\"X-App-Token\"] = self.app_token\n",
    "\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.request(\n",
    "                method=method, url=url, params=params, json=json_data, headers=headers\n",
    "            )\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if response.status_code >= 400 or data.get(\"status\") == \"error\":\n",
    "                error_msg = data.get(\"message\", \"Unknown error\")\n",
    "                raise Exception(f\"API Error ({response.status_code}): {error_msg}\")\n",
    "\n",
    "            return data.get(\"data\")\n",
    "\n",
    "    async def list_projects(\n",
    "        self,\n",
    "        ids: t.Optional[t.List[str]] = None,\n",
    "        limit: int = 50,\n",
    "        offset: int = 0,\n",
    "        order_by: t.Optional[str] = None,\n",
    "        sort_dir: t.Optional[str] = None,\n",
    "    ) -> t.Dict:\n",
    "        params = {\"limit\": limit, \"offset\": offset}\n",
    "\n",
    "        if ids:\n",
    "            params[\"ids\"] = \",\".join(ids)\n",
    "\n",
    "        if order_by:\n",
    "            params[\"order_by\"] = order_by\n",
    "\n",
    "        if sort_dir:\n",
    "            params[\"sort_dir\"] = sort_dir\n",
    "\n",
    "        return await self._request(\"GET\", \"projects\", params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 projects:\n",
      "Error: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": [
    "# Initialize client with your authentication token\n",
    "client = RelayClient(base_url=RAGAS_API_ENDPOINT, app_token=RAGAS_APP_TOKEN)\n",
    "\n",
    "# List projects\n",
    "try:\n",
    "    projects = await client.list_projects(limit=10)\n",
    "    print(f\"Found {len(projects)} projects:\")\n",
    "    for project in projects:\n",
    "        print(f\"- {project['title']} (ID: {project['id']})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def get_project(self: RelayClient, project_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific project by ID.\"\"\"\n",
    "    return await self._request(\"GET\", f\"projects/{project_id}\")\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_project(\n",
    "    self: RelayClient, title: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new project.\"\"\"\n",
    "    data = {\"title\": title}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\"POST\", \"projects\", json_data=data)\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_project(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    title: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing project.\"\"\"\n",
    "    data = {}\n",
    "    if title:\n",
    "        data[\"title\"] = title\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\"PATCH\", f\"projects/{project_id}\", json_data=data)\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_project(self: RelayClient, project_id: str) -> None:\n",
    "    \"\"\"Delete a project.\"\"\"\n",
    "    await self._request(\"DELETE\", f\"projects/{project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6',\n",
       " 'title': 'test project',\n",
       " 'description': 'test description',\n",
       " 'created_at': '2025-03-30T02:33:38.751793+00:00'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_project(\"test project\", \"test description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-03-30T02:33:38.751793+00:00'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 1,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'desc'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROJECT_ID = \"e1b3f1e4-d344-48f4-a178-84e7e32e6ab6\"\n",
    "project = await client.get_project(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_datasets(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List datasets in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\"GET\", f\"projects/{project_id}/datasets\", params=params)\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_dataset(self: RelayClient, project_id: str, dataset_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific dataset.\"\"\"\n",
    "    return await self._request(\"GET\", f\"projects/{project_id}/datasets/{dataset_id}\")\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_dataset(\n",
    "    self: RelayClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new dataset in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\n",
    "        \"POST\", f\"projects/{project_id}/datasets\", json_data=data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_dataset(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing dataset.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\n",
    "        \"PATCH\", f\"projects/{project_id}/datasets/{dataset_id}\", json_data=data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_dataset(self: RelayClient, project_id: str, dataset_id: str) -> None:\n",
    "    \"\"\"Delete a dataset.\"\"\"\n",
    "    await self._request(\"DELETE\", f\"projects/{project_id}/datasets/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e1b3f1e4-d344-48f4-a178-84e7e32e6ab6',\n",
       " 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check project ID\n",
    "projects = await client.list_projects()\n",
    "projects[\"items\"][0][\"id\"], TEST_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset created: {'id': 'dc772b6e-2691-44b9-a6aa-9a0099a37346', 'name': 'New Dataset', 'description': 'This is a new dataset', 'created_at': '2025-03-30T02:35:37.606287+00:00', 'version_counter': 0, 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "new_dataset = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"], \"New Dataset\", \"This is a new dataset\"\n",
    ")\n",
    "print(f\"New dataset created: {new_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 datasets\n"
     ]
    }
   ],
   "source": [
    "# List datasets in the project\n",
    "datasets = await client.list_datasets(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset: {'id': 'dc772b6e-2691-44b9-a6aa-9a0099a37346', 'name': 'Updated Dataset', 'description': 'This is an updated dataset', 'created_at': '2025-03-30T02:35:37.606287+00:00', 'version_counter': 0, 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}\n"
     ]
    }
   ],
   "source": [
    "updated_dataset = await client.update_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"items\"][0][\"id\"],\n",
    "    \"Updated Dataset\",\n",
    "    \"This is an updated dataset\",\n",
    ")\n",
    "print(f\"Updated dataset: {updated_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the dataset\n",
    "await client.delete_dataset(projects[\"items\"][0][\"id\"], datasets[\"items\"][0][\"id\"])\n",
    "print(\"Dataset deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_experiments(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List experiments in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/experiments\", params=params\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_experiment(\n",
    "    self: RelayClient, project_id: str, experiment_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific experiment.\"\"\"\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/experiments/{experiment_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_experiment(\n",
    "    self: RelayClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new experiment in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\n",
    "        \"POST\", f\"projects/{project_id}/experiments\", json_data=data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_experiment(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing experiment.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._request(\n",
    "        \"PATCH\", f\"projects/{project_id}/experiments/{experiment_id}\", json_data=data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_experiment(\n",
    "    self: RelayClient, project_id: str, experiment_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete an experiment.\"\"\"\n",
    "    await self._request(\"DELETE\", f\"projects/{project_id}/experiments/{experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New experiment created: {'id': '17097da4-29e6-4b94-b447-87ef00c21343', 'name': 'New Experiment', 'description': 'This is a new experiment', 'created_at': '2025-03-30T03:03:13.934694+00:00', 'version_counter': 0, 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}\n",
      "Found 2 experiments\n",
      "Experiment: {'id': '17097da4-29e6-4b94-b447-87ef00c21343', 'name': 'New Experiment', 'description': 'This is a new experiment', 'created_at': '2025-03-30T03:03:13.934694+00:00', 'version_counter': 0, 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}\n",
      "Updated experiment: {'id': '17097da4-29e6-4b94-b447-87ef00c21343', 'name': 'Updated Experiment', 'description': 'This is an updated experiment', 'created_at': '2025-03-30T03:03:13.934694+00:00', 'version_counter': 0, 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}\n",
      "Experiment deleted\n"
     ]
    }
   ],
   "source": [
    "# create a new experiment\n",
    "new_experiment = await client.create_experiment(\n",
    "    projects[\"items\"][0][\"id\"], \"New Experiment\", \"This is a new experiment\"\n",
    ")\n",
    "print(f\"New experiment created: {new_experiment}\")\n",
    "# list experiments\n",
    "experiments = await client.list_experiments(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(experiments)} experiments\")\n",
    "# get a specific experiment\n",
    "experiment = await client.get_experiment(\n",
    "    projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"]\n",
    ")\n",
    "print(f\"Experiment: {experiment}\")\n",
    "# update an experiment\n",
    "updated_experiment = await client.update_experiment(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    experiments[\"items\"][0][\"id\"],\n",
    "    \"Updated Experiment\",\n",
    "    \"This is an updated experiment\",\n",
    ")\n",
    "print(f\"Updated experiment: {updated_experiment}\")\n",
    "# delete an experiment\n",
    "await client.delete_experiment(projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"])\n",
    "print(\"Experiment deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 0,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_experiments(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns (for datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API supports the following column types:\n",
    "\n",
    "- `number`: Numeric values\n",
    "- `longText`: Text content\n",
    "- `select`: Single selection from predefined options\n",
    "- `date`: Date values\n",
    "- `multiSelect`: Multiple selections from predefined options\n",
    "- `checkbox`: Boolean values\n",
    "- `custom`: Custom column types with specific behavior\n",
    "\n",
    "Each column type has specific settings that can be configured through the `settings` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "\n",
    "\n",
    "class ColumnType(StrEnum):\n",
    "    NUMBER = \"number\"\n",
    "    TEXT = \"text\"\n",
    "    LONG_TEXT = \"longText\"\n",
    "    SELECT = \"select\"\n",
    "    DATE = \"date\"\n",
    "    MULTI_SELECT = \"multiSelect\"\n",
    "    CHECKBOX = \"checkbox\"\n",
    "    CUSTOM = \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_dataset_columns(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/datasets/{dataset_id}/columns\", params=params\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_dataset_column(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in a dataset.\"\"\"\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_dataset_column(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: str,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"\n",
    "    Create a new column in a dataset.\n",
    "\n",
    "    Raises:\n",
    "        RelayAPIError: If column ID already exists (409 Conflict) or other API errors\n",
    "    \"\"\"\n",
    "    settings = settings or {}\n",
    "    data = {\"id\": id, \"name\": name, \"col_order\": col_order, \"type\": type, \"settings\": settings}\n",
    "    return await self._request(\n",
    "        \"POST\", f\"projects/{project_id}/datasets/{dataset_id}/columns\", json_data=data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_dataset_column(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, column_id: str, **column_data\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in a dataset.\"\"\"\n",
    "    return await self._request(\n",
    "        \"PATCH\",\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\",\n",
    "        json_data=column_data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_column(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from a dataset.\"\"\"\n",
    "    await self._request(\n",
    "        \"DELETE\", f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8',\n",
       " 'name': 'New Dataset for testing columns',\n",
       " 'description': 'This is a new dataset for testing columns',\n",
       " 'created_at': '2025-03-30T03:04:06.619835+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    \"New Dataset for testing columns\",\n",
    "    \"This is a new dataset for testing columns\",\n",
    ")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3',\n",
       " 'type': 'longText',\n",
       " 'settings': {'max_length': 255, 'is_required': True},\n",
       " 'created_at': '2025-03-30T03:04:10.937689+00:00',\n",
       " 'updated_at': '2025-03-30T03:04:10.937689+00:00',\n",
       " 'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column to the dataset\n",
    "new_column = await client.create_dataset_column(\n",
    "    project_id=projects[\"items\"][0][\"id\"],\n",
    "    dataset_id=datasets[\"id\"],\n",
    "    id=\"new_column_3\",\n",
    "    name=\"New Column 3\",\n",
    "    type=ColumnType.TEXT.value,\n",
    "    settings={\n",
    "        \"max_length\": 255,\n",
    "        \"is_required\": True,\n",
    "    },\n",
    ")\n",
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'new_column_3',\n",
       "   'name': 'New Column 3',\n",
       "   'type': 'longText',\n",
       "   'settings': {'max_length': 255, 'is_required': True},\n",
       "   'created_at': '2025-03-30T03:04:10.937689+00:00',\n",
       "   'updated_at': '2025-03-30T03:04:10.937689+00:00',\n",
       "   'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 1,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_dataset_columns(projects[\"items\"][0][\"id\"], datasets[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3',\n",
       " 'type': 'longText',\n",
       " 'settings': {'max_length': 255, 'is_required': True},\n",
       " 'created_at': '2025-03-30T03:04:10.937689+00:00',\n",
       " 'updated_at': '2025-03-30T03:04:10.937689+00:00',\n",
       " 'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col3 = await client.get_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")\n",
    "col3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3 Updated',\n",
       " 'type': 'number',\n",
       " 'settings': {'max_length': 255, 'is_required': True},\n",
       " 'created_at': '2025-03-30T03:04:10.937689+00:00',\n",
       " 'updated_at': '2025-03-30T03:04:33.47167+00:00',\n",
       " 'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.update_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"id\"],\n",
    "    \"new_column_3\",\n",
    "    name=\"New Column 3 Updated\",\n",
    "    type=ColumnType.NUMBER.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.delete_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows (for datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_dataset_rows(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List rows in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/datasets/{dataset_id}/rows\", params=params\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_dataset_row(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific row in a dataset.\"\"\"\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_dataset_row(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new row in a dataset.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._request(\n",
    "        \"POST\", f\"projects/{project_id}/datasets/{dataset_id}/rows\", json_data=row_data\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_dataset_row(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, row_id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing row in a dataset.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._request(\n",
    "        \"PATCH\",\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\",\n",
    "        json_data=row_data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_row(\n",
    "    self: RelayClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from a dataset.\"\"\"\n",
    "    await self._request(\n",
    "        \"DELETE\", f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'data': {'age': 30, 'name': 'New Row 1'},\n",
       " 'created_at': '2025-03-30T03:05:22.502878+00:00',\n",
       " 'updated_at': '2025-03-30T03:05:22.502878+00:00',\n",
       " 'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_dataset_row(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"id\"],\n",
    "    \"1\",\n",
    "    {\"name\": \"New Row 1\", \"age\": 30},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': '1',\n",
       "   'data': {'age': 30, 'name': 'New Row 1'},\n",
       "   'created_at': '2025-03-30T03:05:22.502878+00:00',\n",
       "   'updated_at': '2025-03-30T03:05:22.502878+00:00',\n",
       "   'datatable_id': 'f494bc5a-c80e-4fba-b0ec-a22ad3b4e9d8'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 1,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_dataset_rows(projects[\"items\"][0][\"id\"], datasets[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import string\n",
    "\n",
    "def create_nano_id(size=12):\n",
    "    # Define characters to use (alphanumeric)\n",
    "    alphabet = string.ascii_letters + string.digits\n",
    "    \n",
    "    # Generate UUID and convert to int\n",
    "    uuid_int = uuid.uuid4().int\n",
    "    \n",
    "    # Convert to base62\n",
    "    result = \"\"\n",
    "    while uuid_int:\n",
    "        uuid_int, remainder = divmod(uuid_int, len(alphabet))\n",
    "        result = alphabet[remainder] + result\n",
    "    \n",
    "    # Pad if necessary and return desired length\n",
    "    return result[:size]\n",
    "\n",
    "# Usage\n",
    "nano_id = create_nano_id()  # e.g., \"8dK9cNw3mP5x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nano ID is generally faster\n",
    "from nanoid import generate\n",
    "from uuid import uuid4\n",
    "import timeit\n",
    "\n",
    "def gen_nano():\n",
    "    return generate()\n",
    "\n",
    "def gen_uuid():\n",
    "    return str(uuid4())\n",
    "\n",
    "# Compare performance\n",
    "nano_time = timeit.timeit(gen_nano, number=10000)\n",
    "uuid_time = timeit.timeit(gen_uuid, number=10000)\n",
    "custom_nano_time = timeit.timeit(create_nano_id, number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02608395798597485, 0.019044874992687255, 0.02830641600303352)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nano_time, uuid_time, custom_nano_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Dataset Visualized - Created From UI\n",
    "Lets Create a new dataset and add columns and rows via the endpoint to see how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:3000/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/e2366381-3989-4154-ac91-5a1e75d18bab'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a dataset\n",
    "dataset = await client.create_dataset(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Dataset Visualized from UI\",\n",
    "    description=\"This is a dataset created from the UI\",\n",
    ")\n",
    "\n",
    "# show url\n",
    "WEB_ENDPOINT = \"http://localhost:3000\"\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns\n",
    "columns = await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "# list rows\n",
    "rows = await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'uujCCGzIBwQ2D0K4DL5si',\n",
       "   'name': 'id',\n",
       "   'type': 'number',\n",
       "   'settings': {'id': 'uujCCGzIBwQ2D0K4DL5si',\n",
       "    'name': 'id',\n",
       "    'type': 'number',\n",
       "    'width': 192,\n",
       "    'position': 0,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T16:24:11.001641+00:00',\n",
       "   'updated_at': '2025-03-30T16:24:20.17409+00:00',\n",
       "   'datatable_id': 'e2366381-3989-4154-ac91-5a1e75d18bab'},\n",
       "  {'id': 'HnwarbjjKuEPyZropCJdG',\n",
       "   'name': 'query',\n",
       "   'type': 'text',\n",
       "   'settings': {'id': 'HnwarbjjKuEPyZropCJdG',\n",
       "    'name': 'query',\n",
       "    'type': 'text',\n",
       "    'width': 192,\n",
       "    'position': 1,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T16:24:20.327007+00:00',\n",
       "   'updated_at': '2025-03-30T16:24:29.020552+00:00',\n",
       "   'datatable_id': 'e2366381-3989-4154-ac91-5a1e75d18bab'},\n",
       "  {'id': 'q-iulmBa5tJfewVLmY8HR',\n",
       "   'name': 'persona',\n",
       "   'type': 'select',\n",
       "   'settings': {'id': 'q-iulmBa5tJfewVLmY8HR',\n",
       "    'name': 'persona',\n",
       "    'type': 'select',\n",
       "    'width': 192,\n",
       "    'options': [{'name': 'jithin',\n",
       "      'color': 'hsl(107, 100%, 92%)',\n",
       "      'value': 'jithin'},\n",
       "     {'name': 'ganesh', 'color': 'hsl(267, 100%, 92%)', 'value': 'ganesh'}],\n",
       "    'position': 2,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T16:24:29.205482+00:00',\n",
       "   'updated_at': '2025-03-30T16:29:59.025107+00:00',\n",
       "   'datatable_id': 'e2366381-3989-4154-ac91-5a1e75d18bab'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 3,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'l2t_eNfBJEq713jnolcF-',\n",
       "   'data': {'id': 'l2t_eNfBJEq713jnolcF-',\n",
       "    'HnwarbjjKuEPyZropCJdG': 'This is a test',\n",
       "    'q-iulmBa5tJfewVLmY8HR': 'jithin',\n",
       "    'uujCCGzIBwQ2D0K4DL5si': '1'},\n",
       "   'created_at': '2025-03-30T16:29:27.007777+00:00',\n",
       "   'updated_at': '2025-03-30T16:29:43.17193+00:00',\n",
       "   'datatable_id': 'e2366381-3989-4154-ac91-5a1e75d18bab'},\n",
       "  {'id': 'tmXwh5ePIIPSYfWy6mQHU',\n",
       "   'data': {'id': 'tmXwh5ePIIPSYfWy6mQHU',\n",
       "    'HnwarbjjKuEPyZropCJdG': 'This is another test',\n",
       "    'q-iulmBa5tJfewVLmY8HR': 'ganesh',\n",
       "    'uujCCGzIBwQ2D0K4DL5si': '2'},\n",
       "   'created_at': '2025-03-30T16:29:43.628186+00:00',\n",
       "   'updated_at': '2025-03-30T16:29:59.193342+00:00',\n",
       "   'datatable_id': 'e2366381-3989-4154-ac91-5a1e75d18bab'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 2,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Dataset Visualized - from API\n",
    "\n",
    "we want to be able to use the API with python data like this `t.List[t.Dict]`.\n",
    "```py\n",
    "# how we want the data to look\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"query\": \"What is the capital of Germany?\",\n",
    "        \"persona\": \"Jane\",\n",
    "        \"ground_truth\": \"Berlin\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"query\": \"What is the capital of Italy?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Rome\",\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "columns = {\n",
    "    \"id\": {\"name\": \"id\", \"type\": ColumnType.NUMBER.value, \"id\": create_nano_id()},\n",
    "    \"query\": {\"name\": \"query\", \"type\": ColumnType.TEXT.value, \"id\": create_nano_id()},\n",
    "    \"persona\": {\"name\": \"persona\", \"type\": ColumnType.SELECT.value, \"id\": create_nano_id()},\n",
    "    \"ground_truth\": {\"name\": \"ground_truth\", \"type\": ColumnType.TEXT.value, \"id\": create_nano_id()},\n",
    "}\n",
    "\n",
    "rows = [{\n",
    "    \"id\": {\"data\": \"1\", \"column_id\": columns[\"id\"][\"id\"]},\n",
    "    \"query\": {\"data\": \"What is the capital of France?\", \"column_id\": columns[\"query\"][\"id\"]},\n",
    "    \"persona\": {\"data\": \"John\", \"column_id\": columns[\"persona\"][\"id\"]},\n",
    "    \"ground_truth\": {\"data\": \"Paris\", \"column_id\": columns[\"ground_truth\"][\"id\"]},\n",
    "}, {\n",
    "    \"id\": {\"data\": \"2\", \"column_id\": columns[\"id\"][\"id\"]},\n",
    "    \"query\": {\"data\": \"What is the capital of Germany?\", \"column_id\": columns[\"query\"][\"id\"]},\n",
    "    \"persona\": {\"data\": \"Jane\", \"column_id\": columns[\"persona\"][\"id\"]},\n",
    "    \"ground_truth\": {\"data\": \"Berlin\", \"column_id\": columns[\"ground_truth\"][\"id\"]},\n",
    "}, {\n",
    "    \"id\": {\"data\": \"3\", \"column_id\": columns[\"id\"][\"id\"]},\n",
    "    \"query\": {\"data\": \"What is the capital of Italy?\", \"column_id\": columns[\"query\"][\"id\"]},\n",
    "    \"persona\": {\"data\": \"John\", \"column_id\": columns[\"persona\"][\"id\"]},\n",
    "    \"ground_truth\": {\"data\": \"Rome\", \"column_id\": columns[\"ground_truth\"][\"id\"]},\n",
    "}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {\n",
    "    \"width\": 100,\n",
    "    \"isVisible\": True,\n",
    "    \"isEditable\": True,\n",
    "}\n",
    "# create new dataset\n",
    "dataset = await client.create_dataset(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Dataset Visualized from API\",\n",
    "    description=\"This is a dataset created from the API\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:3000/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/ddebc6ff-95c1-488b-91ca-b29adbe59a6c'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataset url\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete dataset\n",
    "await client.delete_dataset(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns.values():\n",
    "    # copy default settings and add things\n",
    "    await client.create_dataset_column(\n",
    "        project_id=TEST_PROJECT_ID,\n",
    "        dataset_id=dataset[\"id\"],\n",
    "        id=col[\"id\"],\n",
    "        name=col[\"name\"],\n",
    "        type=col[\"type\"],\n",
    "        settings=DEFAULT_SETTINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'gFJjoJ2m3uhZ',\n",
       "   'name': 'id',\n",
       "   'type': 'number',\n",
       "   'settings': {'id': 'gFJjoJ2m3uhZ',\n",
       "    'name': 'id',\n",
       "    'type': 'number',\n",
       "    'width': 100,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T19:23:39.650696+00:00',\n",
       "   'updated_at': '2025-03-30T19:23:39.650696+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'},\n",
       "  {'id': 'eT0gFBhCCYIQ',\n",
       "   'name': 'query',\n",
       "   'type': 'text',\n",
       "   'settings': {'id': 'eT0gFBhCCYIQ',\n",
       "    'name': 'query',\n",
       "    'type': 'text',\n",
       "    'width': 100,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T19:23:40.627392+00:00',\n",
       "   'updated_at': '2025-03-30T19:23:40.627392+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'},\n",
       "  {'id': 'gk8SrPiAqlFm',\n",
       "   'name': 'persona',\n",
       "   'type': 'select',\n",
       "   'settings': {'id': 'gk8SrPiAqlFm',\n",
       "    'name': 'persona',\n",
       "    'type': 'select',\n",
       "    'width': 100,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T19:23:41.26222+00:00',\n",
       "   'updated_at': '2025-03-30T19:23:41.26222+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'},\n",
       "  {'id': 'cCnutJRZqI9J',\n",
       "   'name': 'ground_truth',\n",
       "   'type': 'text',\n",
       "   'settings': {'id': 'cCnutJRZqI9J',\n",
       "    'name': 'ground_truth',\n",
       "    'type': 'text',\n",
       "    'width': 100,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-03-30T19:23:42.023267+00:00',\n",
       "   'updated_at': '2025-03-30T19:23:42.023267+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 4,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list columns\n",
    "await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rows\n",
    "for row in rows:\n",
    "    row_data = {}\n",
    "    # craft row data\n",
    "    for col in row.values():\n",
    "        row_data[col[\"column_id\"]] = col[\"data\"]\n",
    "    await client.create_dataset_row(\n",
    "        project_id=TEST_PROJECT_ID,\n",
    "        dataset_id=dataset[\"id\"],\n",
    "        id=create_nano_id(),\n",
    "        data=row_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'fkDyIAn6OVtW',\n",
       "   'data': {'id': 'fkDyIAn6OVtW',\n",
       "    'cCnutJRZqI9J': 'Paris',\n",
       "    'eT0gFBhCCYIQ': 'What is the capital of France?',\n",
       "    'gFJjoJ2m3uhZ': '1',\n",
       "    'gk8SrPiAqlFm': 'John'},\n",
       "   'created_at': '2025-03-30T19:31:43.850379+00:00',\n",
       "   'updated_at': '2025-03-30T19:31:43.850379+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'},\n",
       "  {'id': 'bGMquZi0i0B6',\n",
       "   'data': {'id': 'bGMquZi0i0B6',\n",
       "    'cCnutJRZqI9J': 'Berlin',\n",
       "    'eT0gFBhCCYIQ': 'What is the capital of Germany?',\n",
       "    'gFJjoJ2m3uhZ': '2',\n",
       "    'gk8SrPiAqlFm': 'Jane'},\n",
       "   'created_at': '2025-03-30T19:31:44.461275+00:00',\n",
       "   'updated_at': '2025-03-30T19:31:44.461275+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'},\n",
       "  {'id': 'bdwIopRvFNI1',\n",
       "   'data': {'id': 'bdwIopRvFNI1',\n",
       "    'cCnutJRZqI9J': 'Rome',\n",
       "    'eT0gFBhCCYIQ': 'What is the capital of Italy?',\n",
       "    'gFJjoJ2m3uhZ': '3',\n",
       "    'gk8SrPiAqlFm': 'John'},\n",
       "   'created_at': '2025-03-30T19:31:45.011852+00:00',\n",
       "   'updated_at': '2025-03-30T19:31:45.011852+00:00',\n",
       "   'datatable_id': 'ddebc6ff-95c1-488b-91ca-b29adbe59a6c'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 3,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list rows\n",
    "await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns (for experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_experiment_columns(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\n",
    "        \"GET\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\",\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_experiment_column(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in an experiment.\"\"\"\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_experiment_column(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: ColumnType,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new column in an experiment.\"\"\"\n",
    "    data = {\"id\": id, \"name\": name, \"col_order\": col_order, \"type\": type}\n",
    "    if settings:\n",
    "        data[\"settings\"] = settings\n",
    "    return await self._request(\n",
    "        \"POST\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\",\n",
    "        json_data=data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_experiment_column(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    column_id: str,\n",
    "    **column_data,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in an experiment.\"\"\"\n",
    "    return await self._request(\n",
    "        \"PATCH\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\",\n",
    "        json_data=column_data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_column(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from an experiment.\"\"\"\n",
    "    await self._request(\n",
    "        \"DELETE\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '78fd6c58-7edf-4239-93d1-4f49185d8e49',\n",
       " 'name': 'New Experiment',\n",
       " 'description': 'This is a new experiment',\n",
       " 'created_at': '2025-03-30T06:31:31.689269+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_experiment(TEST_PROJECT_ID, \"New Experiment\", \"This is a new experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78fd6c58-7edf-4239-93d1-4f49185d8e49'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = await client.list_experiments(TEST_PROJECT_ID)\n",
    "EXPERIMENT_ID = experiments[\"items\"][0][\"id\"]\n",
    "EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "API Error (400): Unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns.values():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m client.create_experiment_column(\n\u001b[32m      3\u001b[39m         project_id=TEST_PROJECT_ID,\n\u001b[32m      4\u001b[39m         experiment_id=EXPERIMENT_ID,\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mid\u001b[39m=col[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m         name=col[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m         \u001b[38;5;28mtype\u001b[39m=col[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mcreate_experiment_column\u001b[39m\u001b[34m(self, project_id, experiment_id, id, name, type, col_order, settings)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m settings:\n\u001b[32m     48\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33msettings\u001b[39m\u001b[33m\"\u001b[39m] = settings\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprojects/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/experiments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/columns\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m     json_data=data,\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mRelayClient._request\u001b[39m\u001b[34m(self, method, endpoint, params, json_data)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code >= \u001b[32m400\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     36\u001b[39m     error_msg = data.get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnknown error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI Error (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: API Error (400): Unknown error"
     ]
    }
   ],
   "source": [
    "for col in columns.values():\n",
    "    await client.create_experiment_column(\n",
    "        project_id=TEST_PROJECT_ID,\n",
    "        experiment_id=EXPERIMENT_ID,\n",
    "        id=col[\"id\"],\n",
    "        name=col[\"name\"],\n",
    "        type=col[\"type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows (for experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "async def list_experiment_rows(\n",
    "    self: RelayClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: Optional[str] = None,\n",
    "    sort_dir: Optional[str] = None,\n",
    ") -> Dict:\n",
    "    \"\"\"List rows in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/experiments/{experiment_id}/rows\", params=params\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def get_experiment_row(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> Dict:\n",
    "    \"\"\"Get a specific row in an experiment.\"\"\"\n",
    "    return await self._request(\n",
    "        \"GET\", f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def create_experiment_row(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, id: str, data: Dict\n",
    ") -> Dict:\n",
    "    \"\"\"Create a new row in an experiment.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._request(\n",
    "        \"POST\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows\",\n",
    "        json_data=row_data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def update_experiment_row(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, row_id: str, data: Dict\n",
    ") -> Dict:\n",
    "    \"\"\"Update an existing row in an experiment.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._request(\n",
    "        \"PATCH\",\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\",\n",
    "        json_data=row_data,\n",
    "    )\n",
    "\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_row(\n",
    "    self: RelayClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from an experiment.\"\"\"\n",
    "    await self._request(\n",
    "        \"DELETE\", f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
