{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Ragas API Client`\n",
    "\n",
    "> Python client to api.ragas.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp backends.ragas_api_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGAS_APP_TOKEN = \"apt.47bd-c55e4a45b27c-02f8-8446-1441f09b-651a8\"\n",
    "RAGAS_API_ENDPOINT = \"https://api.dev.app.ragas.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import httpx\n",
    "import asyncio\n",
    "import functools\n",
    "import typing as t\n",
    "import inspect\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import StrEnum\n",
    "import uuid\n",
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def async_to_sync(async_func):\n",
    "    \"\"\"Convert an async function to a sync function\"\"\"\n",
    "    @functools.wraps(async_func)\n",
    "    def sync_wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                # Thread-based approach for safety\n",
    "                import concurrent.futures\n",
    "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                    future = executor.submit(asyncio.run, async_func(*args, **kwargs))\n",
    "                    return future.result()\n",
    "            else:\n",
    "                return loop.run_until_complete(async_func(*args, **kwargs))\n",
    "        except RuntimeError:\n",
    "            return asyncio.run(async_func(*args, **kwargs))\n",
    "    return sync_wrapper\n",
    "\n",
    "class RagasApiClientMeta(type):\n",
    "    \"\"\"Metaclass that adds sync versions of async methods\"\"\"\n",
    "    def __new__(mcs, name, bases, namespace):\n",
    "        # Create the class\n",
    "        cls = super().__new__(mcs, name, bases, namespace)\n",
    "        \n",
    "        # For each async method, add a sync version\n",
    "        for method_name, method in inspect.getmembers(cls, inspect.iscoroutinefunction):\n",
    "            # Skip magic methods\n",
    "            if method_name.startswith('__') and method_name.endswith('__'):\n",
    "                continue\n",
    "                \n",
    "            # Add a sync version\n",
    "            sync_method_name = f\"{method_name}_sync\"\n",
    "            if not hasattr(cls, sync_method_name):\n",
    "                setattr(cls, sync_method_name, async_to_sync(method))\n",
    "                \n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RagasApiClient(metaclass=RagasApiClientMeta):\n",
    "    \"\"\"Client for the Ragas Relay API.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str, app_token: t.Optional[str] = None):\n",
    "        \"\"\"Initialize the Ragas API client.\n",
    "        \n",
    "        Args:\n",
    "            base_url: Base URL for the API (e.g., \"http://localhost:8087\")\n",
    "            app_token: API token for authentication\n",
    "        \"\"\"\n",
    "        if not app_token:\n",
    "            raise ValueError(\"app_token must be provided\")\n",
    "\n",
    "        self.base_url = f\"{base_url.rstrip('/')}/api/v1\"\n",
    "        self.app_token = app_token\n",
    "\n",
    "    async def _request(\n",
    "        self,\n",
    "        method: str,\n",
    "        endpoint: str,\n",
    "        params: t.Optional[t.Dict] = None,\n",
    "        json_data: t.Optional[t.Dict] = None,\n",
    "    ) -> t.Dict:\n",
    "        \"\"\"Make a request to the API.\n",
    "        \n",
    "        Args:\n",
    "            method: HTTP method (GET, POST, PATCH, DELETE)\n",
    "            endpoint: API endpoint path\n",
    "            params: Query parameters\n",
    "            json_data: JSON request body\n",
    "            \n",
    "        Returns:\n",
    "            The response data from the API\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n",
    "        headers = {\"X-App-Token\": self.app_token}\n",
    "\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.request(\n",
    "                method=method, url=url, params=params, json=json_data, headers=headers\n",
    "            )\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if response.status_code >= 400 or data.get(\"status\") == \"error\":\n",
    "                error_msg = data.get(\"message\", \"Unknown error\")\n",
    "                raise Exception(f\"API Error ({response.status_code}): {error_msg}\")\n",
    "\n",
    "            return data.get(\"data\")\n",
    "\n",
    "    #---- Resource Handlers ----\n",
    "    async def _create_resource(self, path, data):\n",
    "        \"\"\"Generic resource creation.\"\"\"\n",
    "        return await self._request(\"POST\", path, json_data=data)\n",
    "        \n",
    "    async def _list_resources(self, path, **params):\n",
    "        \"\"\"Generic resource listing.\"\"\"\n",
    "        return await self._request(\"GET\", path, params=params)\n",
    "        \n",
    "    async def _get_resource(self, path):\n",
    "        \"\"\"Generic resource retrieval.\"\"\"\n",
    "        return await self._request(\"GET\", path)\n",
    "        \n",
    "    async def _update_resource(self, path, data):\n",
    "        \"\"\"Generic resource update.\"\"\"\n",
    "        return await self._request(\"PATCH\", path, json_data=data)\n",
    "        \n",
    "    async def _delete_resource(self, path):\n",
    "        \"\"\"Generic resource deletion.\"\"\"\n",
    "        return await self._request(\"DELETE\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Projects ----\n",
    "@patch\n",
    "async def list_projects(\n",
    "    self: RagasApiClient,\n",
    "    ids: t.Optional[t.List[str]] = None,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List projects.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "\n",
    "    if ids:\n",
    "        params[\"ids\"] = \",\".join(ids)\n",
    "\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "\n",
    "    return await self._list_resources(\"projects\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_project(self: RagasApiClient, project_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific project by ID.\"\"\"\n",
    "    # TODO: Need get project by title\n",
    "    return await self._get_resource(f\"projects/{project_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_project(\n",
    "    self: RagasApiClient, title: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new project.\"\"\"\n",
    "    data = {\"title\": title}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(\"projects\", data)\n",
    "\n",
    "@patch\n",
    "async def update_project(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    title: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing project.\"\"\"\n",
    "    data = {}\n",
    "    if title:\n",
    "        data[\"title\"] = title\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_project(self: RagasApiClient, project_id: str) -> None:\n",
    "    \"\"\"Delete a project.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 projects:\n",
      "Error: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": [
    "# Initialize client with your authentication token\n",
    "client = RagasApiClient(base_url=RAGAS_API_ENDPOINT, app_token=RAGAS_APP_TOKEN)\n",
    "\n",
    "# List projects\n",
    "try:\n",
    "    projects = await client.list_projects(limit=10)\n",
    "    print(f\"Found {len(projects)} projects:\")\n",
    "    for project in projects:\n",
    "        print(f\"- {project['title']} (ID: {project['id']})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RagasApiClient' object has no attribute 'list_projects_sync'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_projects_sync\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'RagasApiClient' object has no attribute 'list_projects_sync'"
     ]
    }
   ],
   "source": [
    "client.list_projects_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5f892600-e620-448c-a699-aa5971abefdc',\n",
       " 'title': 'test project',\n",
       " 'description': 'test description',\n",
       " 'created_at': '2025-04-09T23:00:39.272415+00:00',\n",
       " 'updated_at': '2025-04-09T23:00:39.272415+00:00'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_project(\"test project\", \"test description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': '5f892600-e620-448c-a699-aa5971abefdc',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-09T23:00:39.272415+00:00',\n",
       "   'updated_at': '2025-04-09T23:00:39.272415+00:00'},\n",
       "  {'id': 'd428d6fc-0348-4208-8187-6fa70ae8115e',\n",
       "   'title': 'My Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-09T22:49:59.790937+00:00',\n",
       "   'updated_at': '2025-04-09T22:49:59.790937+00:00'},\n",
       "  {'id': 'a00d417a-f1dc-4373-ad0e-a3bfff5c3c55',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-09T18:32:42.772189+00:00',\n",
       "   'updated_at': '2025-04-09T18:32:42.772189+00:00'},\n",
       "  {'id': '3b8396ab-592e-4898-bac3-845fe2d5fbd0',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-09T18:31:36.496048+00:00',\n",
       "   'updated_at': '2025-04-09T18:31:36.496048+00:00'},\n",
       "  {'id': '59cf2483-d2c7-4306-af87-bfac2813f27b',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-09T05:57:57.991728+00:00',\n",
       "   'updated_at': '2025-04-09T05:57:57.991728+00:00'},\n",
       "  {'id': 'c026b63c-d618-42c0-81c3-d7824c976eb1',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-08T22:46:04.045516+00:00',\n",
       "   'updated_at': '2025-04-08T22:46:04.045516+00:00'},\n",
       "  {'id': '3dd738de-49f7-494c-aa0a-f6531d3b603a',\n",
       "   'title': 'RagasTest',\n",
       "   'description': '',\n",
       "   'created_at': '2025-04-08T17:45:32.759553+00:00',\n",
       "   'updated_at': '2025-04-08T17:45:32.759553+00:00'},\n",
       "  {'id': '2f45d026-1b13-4851-a36d-c7680edb6380',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-08T14:38:14.61165+00:00',\n",
       "   'updated_at': '2025-04-08T14:38:14.61165+00:00'},\n",
       "  {'id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-03-30T02:33:38.751793+00:00',\n",
       "   'updated_at': '2025-03-30T02:33:38.751793+00:00'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 9,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'desc'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROJECT_ID = \"e1b3f1e4-d344-48f4-a178-84e7e32e6ab6\"\n",
    "project = await client.get_project(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#---- Datasets ----\n",
    "@patch\n",
    "async def list_datasets(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List datasets in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(f\"projects/{project_id}/datasets\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_dataset(self: RagasApiClient, project_id: str, dataset_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific dataset.\"\"\"\n",
    "    return await self._get_resource(f\"projects/{project_id}/datasets/{dataset_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_dataset(\n",
    "    self: RagasApiClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new dataset in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(f\"projects/{project_id}/datasets\", data)\n",
    "\n",
    "@patch\n",
    "async def update_dataset(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing dataset.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}/datasets/{dataset_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_dataset(self: RagasApiClient, project_id: str, dataset_id: str) -> None:\n",
    "    \"\"\"Delete a dataset.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}/datasets/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5f892600-e620-448c-a699-aa5971abefdc',\n",
       " 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check project ID\n",
    "projects = await client.list_projects()\n",
    "projects[\"items\"][0][\"id\"], TEST_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset created: {'id': '43b6c819-3287-419b-a5bd-8423c1600463', 'name': 'New Dataset', 'description': 'This is a new dataset', 'updated_at': '2025-04-09T23:00:42.712663+00:00', 'created_at': '2025-04-09T23:00:42.712663+00:00', 'version_counter': 0, 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "new_dataset = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"], \"New Dataset\", \"This is a new dataset\"\n",
    ")\n",
    "print(f\"New dataset created: {new_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 datasets\n"
     ]
    }
   ],
   "source": [
    "# List datasets in the project\n",
    "datasets = await client.list_datasets(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset: {'id': '43b6c819-3287-419b-a5bd-8423c1600463', 'name': 'Updated Dataset', 'description': 'This is an updated dataset', 'created_at': '2025-04-09T23:00:42.712663+00:00', 'updated_at': '2025-04-09T23:00:44.380877+00:00', 'version_counter': 0, 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}\n"
     ]
    }
   ],
   "source": [
    "updated_dataset = await client.update_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"items\"][0][\"id\"],\n",
    "    \"Updated Dataset\",\n",
    "    \"This is an updated dataset\",\n",
    ")\n",
    "print(f\"Updated dataset: {updated_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the dataset\n",
    "await client.delete_dataset(projects[\"items\"][0][\"id\"], datasets[\"items\"][0][\"id\"])\n",
    "print(\"Dataset deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "#---- Experiments ----\n",
    "@patch\n",
    "async def list_experiments(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List experiments in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(f\"projects/{project_id}/experiments\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_experiment(self: RagasApiClient, project_id: str, experiment_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific experiment.\"\"\"\n",
    "    return await self._get_resource(f\"projects/{project_id}/experiments/{experiment_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_experiment(\n",
    "    self: RagasApiClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new experiment in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(f\"projects/{project_id}/experiments\", data)\n",
    "\n",
    "@patch\n",
    "async def update_experiment(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing experiment.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}/experiments/{experiment_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_experiment(self: RagasApiClient, project_id: str, experiment_id: str) -> None:\n",
    "    \"\"\"Delete an experiment.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}/experiments/{experiment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New experiment created: {'id': 'cb487c5d-ef21-45da-8eab-7a8d3a02b515', 'name': 'New Experiment', 'description': 'This is a new experiment', 'updated_at': '2025-04-09T23:00:45.543119+00:00', 'created_at': '2025-04-09T23:00:45.543119+00:00', 'version_counter': 0, 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}\n",
      "Found 2 experiments\n",
      "Experiment: {'id': 'cb487c5d-ef21-45da-8eab-7a8d3a02b515', 'name': 'New Experiment', 'description': 'This is a new experiment', 'created_at': '2025-04-09T23:00:45.543119+00:00', 'updated_at': '2025-04-09T23:00:45.543119+00:00', 'version_counter': 0, 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}\n",
      "Updated experiment: {'id': 'cb487c5d-ef21-45da-8eab-7a8d3a02b515', 'name': 'Updated Experiment', 'description': 'This is an updated experiment', 'created_at': '2025-04-09T23:00:45.543119+00:00', 'updated_at': '2025-04-09T23:00:47.689729+00:00', 'version_counter': 0, 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}\n",
      "Experiment deleted\n"
     ]
    }
   ],
   "source": [
    "# create a new experiment\n",
    "new_experiment = await client.create_experiment(\n",
    "    projects[\"items\"][0][\"id\"], \"New Experiment\", \"This is a new experiment\"\n",
    ")\n",
    "print(f\"New experiment created: {new_experiment}\")\n",
    "# list experiments\n",
    "experiments = await client.list_experiments(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(experiments)} experiments\")\n",
    "# get a specific experiment\n",
    "experiment = await client.get_experiment(\n",
    "    projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"]\n",
    ")\n",
    "print(f\"Experiment: {experiment}\")\n",
    "# update an experiment\n",
    "updated_experiment = await client.update_experiment(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    experiments[\"items\"][0][\"id\"],\n",
    "    \"Updated Experiment\",\n",
    "    \"This is an updated experiment\",\n",
    ")\n",
    "print(f\"Updated experiment: {updated_experiment}\")\n",
    "# delete an experiment\n",
    "await client.delete_experiment(projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"])\n",
    "print(\"Experiment deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': '78fd6c58-7edf-4239-93d1-4f49185d8e49',\n",
       "   'name': 'New Experiment',\n",
       "   'description': 'This is a new experiment',\n",
       "   'created_at': '2025-03-30T06:31:31.689269+00:00',\n",
       "   'updated_at': '2025-03-30T06:31:31.689269+00:00',\n",
       "   'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'},\n",
       "  {'id': '7c695b58-7fc3-464c-a18b-a96e35f9684d',\n",
       "   'name': 'New Experiment',\n",
       "   'description': 'This is a new experiment',\n",
       "   'created_at': '2025-04-09T17:03:44.340782+00:00',\n",
       "   'updated_at': '2025-04-09T17:03:44.340782+00:00',\n",
       "   'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 2,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_experiments(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns (for datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API supports the following column types:\n",
    "\n",
    "- `number`: Numeric values\n",
    "- `longText`: Text content\n",
    "- `select`: Single selection from predefined options\n",
    "- `date`: Date values\n",
    "- `multiSelect`: Multiple selections from predefined options\n",
    "- `checkbox`: Boolean values\n",
    "- `custom`: Custom column types with specific behavior\n",
    "\n",
    "Each column type has specific settings that can be configured through the `settings` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ColumnType(StrEnum):\n",
    "    NUMBER = \"number\"\n",
    "    TEXT = \"text\"\n",
    "    LONG_TEXT = \"longText\"\n",
    "    SELECT = \"select\"\n",
    "    DATE = \"date\"\n",
    "    MULTI_SELECT = \"multiSelect\"\n",
    "    CHECKBOX = \"checkbox\"\n",
    "    CUSTOM = \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#---- Dataset Columns ----\n",
    "@patch\n",
    "async def list_dataset_columns(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in a dataset.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_dataset_column(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: str,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new column in a dataset.\"\"\"\n",
    "    data = {\"id\": id, \"name\": name, \"type\": type}\n",
    "    if col_order is not None:\n",
    "        data[\"col_order\"] = col_order\n",
    "    if settings:\n",
    "        data[\"settings\"] = settings\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns\", data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str, **column_data\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in a dataset.\"\"\"\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\",\n",
    "        column_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from a dataset.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dd741040-9305-448a-aa4d-7987905a626a',\n",
       " 'name': 'New Dataset for testing columns',\n",
       " 'description': 'This is a new dataset for testing columns',\n",
       " 'updated_at': '2025-04-09T23:00:50.291417+00:00',\n",
       " 'created_at': '2025-04-09T23:00:50.291417+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': '5f892600-e620-448c-a699-aa5971abefdc'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    \"New Dataset for testing columns\",\n",
    "    \"This is a new dataset for testing columns\",\n",
    ")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3',\n",
       " 'type': 'text',\n",
       " 'settings': {'id': 'new_column_3',\n",
       "  'name': 'New Column 3',\n",
       "  'type': 'text',\n",
       "  'max_length': 255,\n",
       "  'is_required': True},\n",
       " 'created_at': '2025-04-09T23:00:50.847325+00:00',\n",
       " 'updated_at': '2025-04-09T23:00:50.847325+00:00',\n",
       " 'datatable_id': 'dd741040-9305-448a-aa4d-7987905a626a'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column to the dataset\n",
    "new_column = await client.create_dataset_column(\n",
    "    project_id=projects[\"items\"][0][\"id\"],\n",
    "    dataset_id=datasets[\"id\"],\n",
    "    id=\"new_column_3\",\n",
    "    name=\"New Column 3\",\n",
    "    type=ColumnType.TEXT.value,\n",
    "    settings={\n",
    "        \"max_length\": 255,\n",
    "        \"is_required\": True,\n",
    "    },\n",
    ")\n",
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'new_column_3',\n",
       "   'name': 'New Column 3',\n",
       "   'type': 'text',\n",
       "   'settings': {'id': 'new_column_3',\n",
       "    'name': 'New Column 3',\n",
       "    'type': 'text',\n",
       "    'max_length': 255,\n",
       "    'is_required': True},\n",
       "   'created_at': '2025-04-09T23:00:50.847325+00:00',\n",
       "   'updated_at': '2025-04-09T23:00:50.847325+00:00',\n",
       "   'datatable_id': 'dd741040-9305-448a-aa4d-7987905a626a'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 1,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_dataset_columns(projects[\"items\"][0][\"id\"], datasets[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3',\n",
       " 'type': 'text',\n",
       " 'settings': {'id': 'new_column_3',\n",
       "  'name': 'New Column 3',\n",
       "  'type': 'text',\n",
       "  'max_length': 255,\n",
       "  'is_required': True},\n",
       " 'created_at': '2025-04-09T23:00:50.847325+00:00',\n",
       " 'updated_at': '2025-04-09T23:00:50.847325+00:00',\n",
       " 'datatable_id': 'dd741040-9305-448a-aa4d-7987905a626a'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col3 = await client.get_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")\n",
    "col3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3 Updated',\n",
       " 'type': 'number',\n",
       " 'settings': {'id': 'new_column_3',\n",
       "  'name': 'New Column 3',\n",
       "  'type': 'text',\n",
       "  'max_length': 255,\n",
       "  'is_required': True},\n",
       " 'created_at': '2025-04-09T23:00:50.847325+00:00',\n",
       " 'updated_at': '2025-04-09T23:00:53.804834+00:00',\n",
       " 'datatable_id': 'dd741040-9305-448a-aa4d-7987905a626a'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.update_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"id\"],\n",
    "    \"new_column_3\",\n",
    "    name=\"New Column 3 Updated\",\n",
    "    type=ColumnType.NUMBER.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.delete_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows (for datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Dataset Rows ----\n",
    "@patch\n",
    "async def list_dataset_rows(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List rows in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific row in a dataset.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new row in a dataset.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows\", row_data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing row in a dataset.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\",\n",
    "        row_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from a dataset.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Dataset Visualized - Created From UI\n",
    "Lets Create a new dataset and add columns and rows via the endpoint to see how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.app.ragas.io/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/dbccf6aa-b923-47ed-8e97-bd46f2f2cee8'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a dataset\n",
    "dataset = await client.create_dataset(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Dataset Visualized from UI\",\n",
    "    description=\"This is a dataset created from the UI\",\n",
    ")\n",
    "\n",
    "# show url\n",
    "WEB_ENDPOINT = \"https://dev.app.ragas.io\"\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns\n",
    "columns = await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "# list rows\n",
    "rows = await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 0,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 0,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset from data\n",
    "\n",
    "we want to be able to use the API with python data like this `t.List[t.Dict]`.\n",
    "```py\n",
    "# how we want the data to look\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"query\": \"What is the capital of Germany?\",\n",
    "        \"persona\": \"Jane\",\n",
    "        \"ground_truth\": \"Berlin\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"query\": \"What is the capital of Italy?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Rome\",\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number', 'text', 'longText', 'select', 'date', 'multiSelect', 'checkbox', 'custom']\n"
     ]
    }
   ],
   "source": [
    "# print out column types\n",
    "print([col.value for col in ColumnType])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should be able to handle simple python dicts\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"query\": \"What is the capital of Germany?\",\n",
    "        \"persona\": \"Jane\",\n",
    "        \"ground_truth\": \"Berlin\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be 2 ways to pass in data\n",
    "\n",
    "1. Data can come as either as simple dicts\n",
    "\n",
    "```py\n",
    "data = [\n",
    "    {\"column_1\": \"value\", \"column_2\": \"value\"}\n",
    "]\n",
    "```\n",
    "\n",
    "2. or if you want to give more settings\n",
    "\n",
    "```py\n",
    "data = [\n",
    "    {\n",
    "        \"column_1\": {\"data\": \"value\", \"type\": ColumnType.text},\n",
    "        \"column_2\": {\"data\": \"value\", \"type\": ColumnType.number},\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "3. after that you will have to pass a list `Column` and `Row` to add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data_columns = [\n",
    "    {\"name\": \"id\", \"type\": ColumnType.NUMBER.value},\n",
    "    {\"name\": \"query\", \"type\": ColumnType.TEXT.value},\n",
    "    {\"name\": \"persona\", \"type\": ColumnType.TEXT.value},\n",
    "    {\"name\": \"ground_truth\", \"type\": ColumnType.TEXT.value},\n",
    "]\n",
    "\n",
    "test_data_rows = [{\n",
    "    \"id\": \"1\",\n",
    "    \"query\": \"What is the capital of France?\",\n",
    "    \"persona\": \"John\",\n",
    "    \"ground_truth\": \"Paris\",\n",
    "}, {\n",
    "    \"id\": \"2\",\n",
    "    \"query\": \"What is the capital of Germany?\",\n",
    "    \"persona\": \"Jane\",\n",
    "    \"ground_truth\": \"Berlin\",\n",
    "}, {\n",
    "    \"id\": \"3\",\n",
    "    \"query\": \"What is the capital of Italy?\",\n",
    "    \"persona\": \"John\",\n",
    "    \"ground_truth\": \"Rome\",\n",
    "}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uuid\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_nano_id(size=12):\n",
    "    # Define characters to use (alphanumeric)\n",
    "    alphabet = string.ascii_letters + string.digits\n",
    "    \n",
    "    # Generate UUID and convert to int\n",
    "    uuid_int = uuid.uuid4().int\n",
    "    \n",
    "    # Convert to base62\n",
    "    result = \"\"\n",
    "    while uuid_int:\n",
    "        uuid_int, remainder = divmod(uuid_int, len(alphabet))\n",
    "        result = alphabet[remainder] + result\n",
    "    \n",
    "    # Pad if necessary and return desired length\n",
    "    return result[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anvz5k9geU7T'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "nano_id = create_nano_id()  # e.g., \"8dK9cNw3mP5x\"\n",
    "nano_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Default settings for columns\n",
    "DEFAULT_SETTINGS = {\n",
    "    \"is_required\": False,\n",
    "    \"max_length\": 1000\n",
    "}\n",
    "\n",
    "# Model definitions\n",
    "class Column(BaseModel):\n",
    "    id: str = Field(default_factory=create_nano_id)\n",
    "    name: str = Field(...)\n",
    "    type: str = Field(...)\n",
    "    settings: t.Dict = Field(default_factory=lambda: DEFAULT_SETTINGS.copy())\n",
    "    col_order: t.Optional[int] = Field(default=None)\n",
    "\n",
    "class RowCell(BaseModel):\n",
    "    data: t.Any = Field(...)\n",
    "    column_id: str = Field(...)\n",
    "\n",
    "class Row(BaseModel):\n",
    "    id: str = Field(default_factory=create_nano_id)\n",
    "    data: t.List[RowCell] = Field(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Resource With Data Helper Methods ----\n",
    "@patch\n",
    "async def _create_with_data(\n",
    "    self: RagasApiClient,\n",
    "    resource_type: str,\n",
    "    project_id: str,\n",
    "    name: str, \n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Generic method to create a resource with columns and rows.\n",
    "    \n",
    "    Args:\n",
    "        resource_type: Type of resource (\"dataset\" or \"experiment\")\n",
    "        project_id: Project ID\n",
    "        name: Resource name\n",
    "        description: Resource description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created resource\n",
    "    \"\"\"\n",
    "    # Select appropriate methods based on resource type\n",
    "    if resource_type == \"dataset\":\n",
    "        create_fn = self.create_dataset\n",
    "        create_col_fn = self.create_dataset_column\n",
    "        create_row_fn = self.create_dataset_row\n",
    "        delete_fn = self.delete_dataset\n",
    "        id_key = \"dataset_id\"\n",
    "    elif resource_type == \"experiment\":\n",
    "        create_fn = self.create_experiment\n",
    "        create_col_fn = self.create_experiment_column\n",
    "        create_row_fn = self.create_experiment_row\n",
    "        delete_fn = self.delete_experiment\n",
    "        id_key = \"experiment_id\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported resource type: {resource_type}\")\n",
    "        \n",
    "    try:\n",
    "        # Create the resource\n",
    "        resource = await create_fn(project_id, name, description)\n",
    "        \n",
    "        # Process columns in batches\n",
    "        for i in range(0, len(columns), batch_size):\n",
    "            batch = columns[i:i+batch_size]\n",
    "            col_tasks = []\n",
    "            \n",
    "            for col in batch:\n",
    "                params = {\n",
    "                    \"project_id\": project_id,\n",
    "                    id_key: resource[\"id\"], # dataset_id here\n",
    "                    \"id\": col.id,\n",
    "                    \"name\": col.name,\n",
    "                    \"type\": col.type,\n",
    "                    \"settings\": col.settings\n",
    "                }\n",
    "                if col.col_order is not None:\n",
    "                    params[\"col_order\"] = col.col_order\n",
    "                \n",
    "                col_tasks.append(create_col_fn(**params))\n",
    "            \n",
    "            await asyncio.gather(*col_tasks)\n",
    "            \n",
    "        # Process rows in batches\n",
    "        for i in range(0, len(rows), batch_size):\n",
    "            batch = rows[i:i+batch_size]\n",
    "            row_tasks = []\n",
    "            \n",
    "            for row in batch:\n",
    "                row_data = {cell.column_id: cell.data for cell in row.data}\n",
    "                row_tasks.append(\n",
    "                    create_row_fn(\n",
    "                        project_id=project_id,\n",
    "                        **{id_key: resource[\"id\"]},\n",
    "                        id=row.id,\n",
    "                        data=row_data\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            await asyncio.gather(*row_tasks)\n",
    "            \n",
    "        return resource\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up on error\n",
    "        if 'resource' in locals():\n",
    "            try:\n",
    "                await delete_fn(project_id, resource[\"id\"])\n",
    "            except:\n",
    "                pass  # Ignore cleanup errors\n",
    "        raise e\n",
    "\n",
    "@patch\n",
    "async def create_dataset_with_data(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    name: str,\n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a dataset with columns and rows.\n",
    "    \n",
    "    This method creates a dataset and populates it with columns and rows in an\n",
    "    optimized way using concurrent requests.\n",
    "    \n",
    "    Args:\n",
    "        project_id: Project ID\n",
    "        name: Dataset name\n",
    "        description: Dataset description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created dataset\n",
    "    \"\"\"\n",
    "    return await self._create_with_data(\n",
    "        \"dataset\", project_id, name, description, columns, rows, batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with ID: 5e7912f4-6a65-4d0c-bf79-0fab9ddda40c\n",
      "Created 4 columns\n",
      "Created 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Create Column objects\n",
    "column_objects = []\n",
    "for col in test_data_columns:\n",
    "    column_objects.append(Column(\n",
    "        name=col[\"name\"],\n",
    "        type=col[\"type\"]\n",
    "        # id and settings will be auto-generated\n",
    "    ))\n",
    "\n",
    "# Create a mapping of column names to their IDs for creating rows\n",
    "column_map = {col.name: col.id for col in column_objects}\n",
    "\n",
    "# Create Row objects\n",
    "row_objects = []\n",
    "for row in test_data_rows:\n",
    "    cells = []\n",
    "    for key, value in row.items():\n",
    "        if key in column_map:  # Skip any extra fields not in columns\n",
    "            cells.append(RowCell(\n",
    "                data=value,\n",
    "                column_id=column_map[key]\n",
    "            ))\n",
    "    row_objects.append(Row(data=cells))\n",
    "\n",
    "# Now we can create the dataset\n",
    "dataset = await client.create_dataset_with_data(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Capitals Dataset\",\n",
    "    description=\"A dataset about capital cities\",\n",
    "    columns=column_objects,\n",
    "    rows=row_objects\n",
    ")\n",
    "\n",
    "print(f\"Created dataset with ID: {dataset['id']}\")\n",
    "\n",
    "# Verify the data\n",
    "columns = await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "print(f\"Created {len(columns['items'])} columns\")\n",
    "\n",
    "rows = await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "print(f\"Created {len(rows['items'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.app.ragas.io/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/5e7912f4-6a65-4d0c-bf79-0fab9ddda40c'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataset url\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "await client.delete_dataset(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same but for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Experiment Columns ----\n",
    "@patch\n",
    "async def list_experiment_columns(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in an experiment.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_experiment_column(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: str,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new column in an experiment.\"\"\"\n",
    "    data = {\"id\": id, \"name\": name, \"type\": type}\n",
    "    if col_order is not None:\n",
    "        data[\"col_order\"] = col_order\n",
    "    if settings:\n",
    "        data[\"settings\"] = settings\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\", data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str, **column_data\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in an experiment.\"\"\"\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\",\n",
    "        column_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from an experiment.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "#---- Experiment Rows ----\n",
    "@patch\n",
    "async def list_experiment_rows(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List rows in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific row in an experiment.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new row in an experiment.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows\", row_data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing row in an experiment.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\",\n",
    "        row_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from an experiment.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7c695b58-7fc3-464c-a18b-a96e35f9684d',\n",
       " 'name': 'New Experiment',\n",
       " 'description': 'This is a new experiment',\n",
       " 'updated_at': '2025-04-09T17:03:44.340782+00:00',\n",
       " 'created_at': '2025-04-09T17:03:44.340782+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_experiment(TEST_PROJECT_ID, \"New Experiment\", \"This is a new experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78fd6c58-7edf-4239-93d1-4f49185d8e49'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = await client.list_experiments(TEST_PROJECT_ID)\n",
    "EXPERIMENT_ID = experiments[\"items\"][0][\"id\"]\n",
    "EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def create_experiment_with_data(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    name: str,\n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create an experiment with columns and rows.\n",
    "    \n",
    "    This method creates an experiment and populates it with columns and rows in an\n",
    "    optimized way using concurrent requests.\n",
    "    \n",
    "    Args:\n",
    "        project_id: Project ID\n",
    "        name: Experiment name\n",
    "        description: Experiment description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created experiment\n",
    "    \"\"\"\n",
    "    return await self._create_with_data(\n",
    "        \"experiment\", project_id, name, description, columns, rows, batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Utility Methods ----\n",
    "@patch\n",
    "def create_column(\n",
    "    self: RagasApiClient, \n",
    "    name: str, \n",
    "    type: str, \n",
    "    settings: t.Optional[t.Dict] = None, \n",
    "    col_order: t.Optional[int] = None,\n",
    "    id: t.Optional[str] = None\n",
    ") -> Column:\n",
    "    \"\"\"Create a Column object.\n",
    "    \n",
    "    Args:\n",
    "        name: Column name\n",
    "        type: Column type (use ColumnType enum)\n",
    "        settings: Column settings\n",
    "        col_order: Column order\n",
    "        id: Custom ID (generates one if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Column object\n",
    "    \"\"\"\n",
    "    params = {\"name\": name, \"type\": type}\n",
    "    if settings:\n",
    "        params[\"settings\"] = settings\n",
    "    if col_order is not None:\n",
    "        params[\"col_order\"] = col_order\n",
    "    if id:\n",
    "        params[\"id\"] = id\n",
    "        \n",
    "    return Column(**params)\n",
    "    \n",
    "@patch\n",
    "def create_row(\n",
    "    self: RagasApiClient, \n",
    "    data: t.Dict[str, t.Any], \n",
    "    column_map: t.Dict[str, str],\n",
    "    id: t.Optional[str] = None\n",
    ") -> Row:\n",
    "    \"\"\"Create a Row object from a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary mapping column names to values\n",
    "        column_map: Dictionary mapping column names to column IDs\n",
    "        id: Custom ID (generates one if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Row object\n",
    "    \"\"\"\n",
    "    cells = []\n",
    "    for col_name, value in data.items():\n",
    "        if col_name in column_map:\n",
    "            cells.append(RowCell(\n",
    "                data=value,\n",
    "                column_id=column_map[col_name]\n",
    "            ))\n",
    "            \n",
    "    params = {\"data\": cells}\n",
    "    if id:\n",
    "        params[\"id\"] = id\n",
    "        \n",
    "    return Row(**params)\n",
    "    \n",
    "@patch\n",
    "def create_column_map(self: RagasApiClient, columns: t.List[Column]) -> t.Dict[str, str]:\n",
    "    \"\"\"Create a mapping of column names to IDs.\n",
    "    \n",
    "    Args:\n",
    "        columns: List of column objects\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping column names to IDs\n",
    "    \"\"\"\n",
    "    return {col.name: col.id for col in columns}\n",
    "    \n",
    "@patch\n",
    "async def convert_raw_data(\n",
    "    self: RagasApiClient,\n",
    "    column_defs: t.List[t.Dict],\n",
    "    row_data: t.List[t.Dict]\n",
    ") -> t.Tuple[t.List[Column], t.List[Row]]:\n",
    "    \"\"\"Convert raw data to column and row objects.\n",
    "    \n",
    "    Args:\n",
    "        column_defs: List of column definitions (dicts with name, type)\n",
    "        row_data: List of dictionaries with row data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (columns, rows)\n",
    "    \"\"\"\n",
    "    # Create columns\n",
    "    columns = []\n",
    "    for col in column_defs:\n",
    "        columns.append(self.create_column(**col))\n",
    "        \n",
    "    # Create column map\n",
    "    column_map = self.create_column_map(columns)\n",
    "    \n",
    "    # Create rows\n",
    "    rows = []\n",
    "    for data in row_data:\n",
    "        rows.append(self.create_row(data, column_map))\n",
    "        \n",
    "    return columns, rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
